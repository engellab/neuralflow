{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "This is an example that reproduces Figure 3 in the main text (up to iteration 50).\n",
    "It also calculates validated negative loglikelihood at each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuralflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt, matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate synthetic data\n",
    "\n",
    "1) Specify the ground-truth model for data generation, see the implementation of the `EnergyModel` class for available options.\n",
    "Here we use the spectral elements method (SEM) for the eigenvector-eigenvalue problem with `Ne=256` elements and `Np=8` points per element. We retain `Nv=64` eigenvectors and eigenvalues of the $\\mathcal{H}$ operator for the likelihood and gradients calculations. We use double-well model (as in main text FIG. 3, 4), noise magnitude `D0=10`, 1 neural response with the firing rate function `f(x) = 100*(x+1)` hz. We represent the results by plotting model potential, use equilibrium probability distribution peq$=\\exp(-\\Phi(x))$ to save the results, and optimize the driving force $F(x)$. All these quantities are equivalent parameterization of the latent model, see Supplementary Information 1.1 for the details.\n",
    "\n",
    "2) Specify data generation parameters. Here we generate two trials of duration `100` seconds with the temporal resolution for latent trajectories `deltaT = 0.0001`. \n",
    "\n",
    "3) Perform data generation, and split the generated data into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:26<00:00, 13.29s/it]\n"
     ]
    }
   ],
   "source": [
    "EnergyModelParams={'pde_solve_param':{'method':{'name': 'SEM', 'gridsize': {'Np': 8, 'Ne': 256}}}, \n",
    "               'Nv': 64, \n",
    "               'peq_model':{\"model\": \"double_well\", \"params\": {\"xmin\": 0.6, \"xmax\": 0.0, \"depth\": 2}},\n",
    "               'D0': 10, \n",
    "               'num_neuron':1,\n",
    "               'firing_model':[{\"model\": \"rectified_linear\", \"params\": {\"r_slope\": 100, \"x_thresh\": -1}}],\n",
    "               'verbose':True\n",
    "               }\n",
    " \n",
    "data_gen_params={'deltaT':0.0001, 'time_epoch':  [(0,100)]*2}\n",
    "\n",
    "#Initialise ground-truth em class\n",
    "em_gt=neuralflow.EnergyModel(**EnergyModelParams)\n",
    "\n",
    "#Save the ground-truth for visulalization\n",
    "peq_gt=np.copy(em_gt.peq_)\n",
    "\n",
    "#Generate data\n",
    "data, time_bins, diff_traj=em_gt.generate_data(**data_gen_params)\n",
    "\n",
    "#Split the data into training and validation set\n",
    "dataTR=data[[0]]\n",
    "dataCV=data[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Perform model optimization\n",
    "1) Create another instance of `EnergyModel` that will be used for model fitting. This instance is the same as the ground-truth but with different equilibrium probability distribution `peq`. In this case, `peq` serves as the initial guess.\n",
    "\n",
    "2) Define fitting parameters. Here we use Gradient descent optimizer (`GD`), limit the optimization to 50 iteration, set the learning rate to `0.005`, `loglik_tol` to zero (so that optimization will not terminate due to small changes of relative loglikelihood), `etaf` to zero (so that there is no cost function regularizer), and specify validation data.\n",
    "\n",
    "3) Perform fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnergyModelParams={'pde_solve_param':{'method':{'name': 'SEM', 'gridsize': {'Np': 8, 'Ne': 256}}}, \n",
    "               'Nv': 64, \n",
    "               'peq_model':{\"model\": \"cos_square\", \"params\": {}},\n",
    "               'D0': 10, \n",
    "               'num_neuron':1,\n",
    "               'firing_model':[{\"model\": \"rectified_linear\", \"params\": {\"r_slope\": 100, \"x_thresh\": -1}}],\n",
    "               'verbose':True\n",
    "               }\n",
    "em_fitting=neuralflow.EnergyModel(**EnergyModelParams)\n",
    "\n",
    "fitting_params={'optimizer':'GD', \n",
    "               'options':{'max_iteration': 50, 'gamma': {'F': 0.005},  'loglik_tol':0.0, 'etaf': 0, 'dataCV': dataCV}}\n",
    "    \n",
    "em_fitting.fit(dataTR,**fitting_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls=em_fitting.iterations_GD_['logliks']\n",
    "lls_CV=em_fitting.iterations_GD_['logliksCV']\n",
    "\n",
    "#Shift training and validated loglikelihoods such that they both start from 0 for visualisation purposes\n",
    "lls= (lls-lls[0])\n",
    "lls_CV=(lls_CV-lls_CV[0])\n",
    "\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "gridspec.GridSpec(2,4)\n",
    "Iterations=[1,6,13,50]\n",
    "colors=[[0.0, 0.0, 1.0],\n",
    "        [0.2, 0.4, 0.8],\n",
    "        [0.4, 0.2, 0.6],\n",
    "        [0.6, 0.2, 0.4]]\n",
    "\n",
    "# Plot negative loglikelihood vs. iteration number\n",
    "plt.subplot2grid((2,4), (0,0), colspan=2, rowspan=2)\n",
    "\n",
    "plt.plot(np.arange(1,lls.size+1),lls,color='black',linewidth=3,label='training')\n",
    "plt.plot(np.arange(1,lls_CV.size+1),lls_CV,color='red',linewidth=3, label='validation')\n",
    "plt.xlabel('Iteration #', fontsize=18)\n",
    "plt.ylabel(r'$-\\log\\mathcal{L}$', fontsize=18)\n",
    "plt.legend()\n",
    "\n",
    "#Point at iteration with minCV\n",
    "minCV, ysize=np.argmin(lls_CV)+1, -np.min(lls_CV)/5\n",
    "plt.arrow(minCV,lls_CV[minCV-1]+ysize,0,-ysize*0.9,width=0.25,length_includes_head=True,head_width=1.5,head_length=10, color='red')\n",
    "\n",
    "#Plot potentials. Potential is calculated from peq by taking negative log: Phi = - log(peq). \n",
    "for i,Iter in enumerate(Iterations):\n",
    "    plt.subplot2grid((2,4), (i//2,2+i%2))\n",
    "    plt.plot(em_fitting.x_d_,np.minimum(-np.log(em_fitting.iterations_GD_['peqs'][...,Iterations[i]-1]),6),color=colors[i],linewidth=3)\n",
    "    plt.plot(em_fitting.x_d_,np.minimum(-np.log(peq_gt),6),color='grey',linewidth=2)\n",
    "    plt.title('Iteration {}'.format(Iterations[i])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above should produce the following image:\n",
    "![Jupyter notebook icon](Example1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
